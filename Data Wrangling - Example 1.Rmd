---
title: "Data Wrangling - Example 1"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---
# Tidying up a messed up data table from a real study

## Client description of the job:
___

> Looking for an experienced R programmer who takes pride in writing elegant, efficient code to melt a long dataframe into wide. I'd rather someone take a few hours to write elegant code than to simply get it done quickly. I found myself writing ugly code to solve this, and would like to see a solution that avoids messy loops and hacks.
>
This reshape involves the attached csv file ('messy_melt.csv'). The basic task is to melt this wide form data into long form. However, this is data from an actual experiment, so is messier than the `airquality` dataset.
>
The data from the experiment were recorded in wide format. In the experiment, each subject saw 10 pairs of vignettes and chose the element in the pair most associated with eight different traits. Concurrently, for each vignette-pair, they were assigned to one of three treatment conditions. So, each subject made 80 choices in total (8 choices for each of the 10 pairs).
>
However, the data were recorded in wide format, as follows. In the accompanying dataframe, each row corresponds to a subject. I.E., each row has a unique ID, denoted in the column 'ID'. The remaining columns denote each of the 80 choices (8 for each of the 10 vignette pairs) made by that subject, along with the treatment that they were assigned for each vignette pair (10 treatments).
>
Additionally, the order of each vignette pair was randomized. This information should be discarded.
>
For example: column 'angry8a' indicates the choice made by subjects on the 8th vignette pair, according to which element in the pair is most associated with anger. 'angry8b' denotes the same, except for subjects assigned to see the two vignettes in the pair in opposite order. These two columns can be merged; no subjects have responses to both 'angry8a' and 'angry8b', and the vignette order is not important to the study.
>
The desired output is a dataframe with the following columns.
['ID', 'VignettePair', 'Trait', 'Assignment', 'Choice']
>
'ID' is the subjects ID. Each unique ID will occur 80 times in the long-form data.
>
'VignettePair' indexes the 10 pairs of vignettes.
>
'Trait' refers to the trait on which the pairs were compared (angry, proud, knowledge, etc, 8 in total).
>
'Assignment' is the treatment condition for each vignette pair. This is recorded in the data in a series of columns called 'rand_[VignettePair]_assignment', where VignettePair pair is the index of the vignette pair to which that column refers.
>
'Choice' is the choice that the subject made when choosing between that pair ('Statement A' or 'Statement B').
>
The ideal candidate will deliver a simple, elegant solution. This can be done hourly or as a fixed price contract, whichever is preferred.

___

```{r, echo=FALSE, include=FALSE}
require(tidyverse)
```

```{r, echo=FALSE, include=FALSE}
data <- read_csv("messy_melt.csv")
```

### This is an example of how the client data set initially looks:

___

```{r, echo=FALSE}
head(data,n = 10)
```
___

As you can see, some columns are actually values instead of variables, and not only this, the very names of the columns contain more than one variable value. In addition, the results from the study are scattered around.

My current approach to this job is:

- Separate the test types into two sets of data (one for each test type), so then i could easily coalesce the data to fill the empty cells while also adding a variable to describe the test type. In the process, i'll also correctly rename the columns of both sets of data to match each other since the type of test was already moved into a new column.

- Check, assign and verify the subjects IDs from the original data set to the new one

- Convert from Wide format to Long format, so the data can be easily visualized and tested

- Add the "VignettePair" and "Assigment" variables using IDs as references

- Lastly, the final data set will be generated by merging the previously generated data sets in relation to the "IDs" and "VignettePair" variables since these are the common columns

___

```{r, echo=FALSE, include=FALSE}
#Separate test types a and b (for join simplicity)

a <- data %>% select(ends_with("a"))

b <- data %>% select(ends_with("b"))

#Rename columns (remove the a and b)

names(a) <- a %>% colnames() %>% str_sub(0,-2)

names(b) <- b %>% colnames() %>% str_sub(0,-2)

#"Merge" (NAs will be filled)

test <- coalesce(a,b)

#Add ID

test <- cbind(data[,"ID"],test)

#"Longify"! :)

test <- test %>% gather(Trait,"Choice",2:81) %>% mutate(VignettePair = as.numeric(str_remove_all(Trait,"[a-z]")), Trait = str_remove_all(Trait,"[0-9]"))

#Obtain VignettePair and Assignment (related to ID)

test2 <- data %>% select("ID",starts_with("rand")) %>% gather(VignettePair,"Assignment",2:11) %>% mutate(VignettePair = as.numeric(sub("_$","",str_sub(VignettePair,6,7))))

#Merge all by ID and VignettePair (common columns)

final <- merge(test,test2)

```
___

### This is the final result:

```{r, echo=FALSE}
head(final,n = 10)
```
___

### The 80 columns were summarized into the actual 5 variables of the Study. The data set can now be easily analyzed, visualized and exported into different formats.

___
Code can be consulted in: https://github.com/Rizcalla/Data-Wrangling---Example-1.git